![Beezle Bug Banner](imgs/banner.jpeg)

# Beezle Bug

> *A visual agent graph builder inspired by the AI companion from Tad Williams' [Otherland](https://en.wikipedia.org/wiki/Otherland) series*

**Beezle Bug** is a local-first, visual tool for building and orchestrating AI agent systems. Design multi-agent workflows with a node-based editor, connect agents to knowledge graphs and memory streams, and deploy them instantlyâ€”all from a modern dark-themed interface.

## ğŸ¯ Features

- **Visual Node Graph Editor** â€“ Drag-and-drop interface for building agent pipelines
- **Multi-Agent Orchestration** â€“ Create and connect multiple specialized agents
- **Knowledge Graphs** â€“ Persistent entity-relationship storage for agent memory
- **Memory Streams** â€“ Observation-based short-term memory for agents
- **Template System** â€“ Jinja2 templates for agent system prompts
- **Scheduled Events** â€“ Timer-based autonomous agent triggering
- **Text-to-Speech** â€“ Integrated Piper TTS with voice selection
- **Voice Input** â€“ Wake word-activated speech-to-text with Whisper
- **Real-time Introspection** â€“ Watch agent reasoning in real-time
- **Fully Local or Cloud** â€“ Run entirely on your machine with local LLMs, or connect to remote APIs via LiteLLM

---

## ğŸ“¸ Interface Overview

Beezle Bug features a three-column layout with resizable panels:

### Interface

![Main Interface](imgs/screenshots/main_interface.png)
*The full Beezle Bug interface showing all panels*

---

### 1. Menu Bar

The top menu bar provides:
- **Project Selector** â€“ Create, load, and switch between projects
- **Save/Delete** â€“ Quick actions for project management
- **Deploy/Stop** â€“ One-click deployment of your agent graph

---

### 2. Neural Stream (Left Panel - Top)

Real-time introspection of agent activity:
- **Message events** â€“ When agents receive input
- **Thinking** â€“ LLM reasoning in progress
- **Tool calls** â€“ Tools being selected and executed
- **Filtering** â€“ Filter by agent or event type
- **Expandable events** â€“ Click to see full details

---

### 3. Log Panel (Left Panel - Bottom)

System logs with color-coded entries:
- âœ… Success messages (green)
- â„¹ï¸ Info messages (blue)
- âš ï¸ Warnings (yellow)
- âŒ Errors (red)

---

### 4. Chat Tab (Center Panel)

Conversation interface with deployed agents:
- **Markdown support** â€“ Code blocks, lists, links
- **Audio playback** â€“ TTS-generated responses
- **Voice input indicator** â€“ Shows listening state (idle/active)
- **User input** â€“ Send messages via text or voice

---

### 5. Node Graph Tab (Center Panel)

Visual editor for building agent pipelines:

| Node Type | Description |
|-----------|-------------|
| ğŸ¤– **Agent** | LLM-powered agent with configurable model and template |
| ğŸ§  **Knowledge Graph** | Persistent entity-relationship storage |
| ğŸ’¾ **Memory Stream** | Observation-based memory buffer |
| ğŸ”§ **Toolbox** | Collection of tools an agent can use |
| ğŸ’¬ **User Chat** | Input from the user interface |
| ğŸ–¥ï¸ **User Display** | Output to the chat interface |
| â° **Scheduled Event** | Timer trigger for autonomous operation |
| ğŸ”€ **Wait & Combine** | Rendezvous point that waits for all inputs before forwarding |

**Connection Types:**
- **Message** (blue) â€“ Agent-to-agent or event-to-agent communication
- **Pipeline** (green) â€“ Data flow
- **Resource** (purple, dashed) â€“ Shared resources
- **Delegate** (orange, dashed) â€“ Task delegation

---

### 6. Template Editor Tab (Center Panel)

Edit and manage Jinja2 templates for agent system prompts:
- **Template list** â€“ All available templates
- **Syntax highlighting** â€“ Jinja2 + Markdown
- **Create/Save/Delete** â€“ Full template management
- **Unsaved changes indicator** â€“ Visual feedback

Built-in templates include:
- `agent.j2` â€“ General-purpose agent
- `researcher.j2` â€“ Research-focused agent
- `planner.j2` â€“ Task planning agent
- `python_programmer.j2` â€“ Code-focused agent
- `summarizer.j2` â€“ Text summarization
- And more...

---

### 7. Settings Panel (Right Panel - Top)

Tabbed configuration interface:

#### Agents Tab
View and manage running agent instances.

#### Node Inspector Tab

Configure the selected node's properties:
- Agent: Model, API URL, system template
- Knowledge Graph: Name
- Memory Stream: Max observations
- Toolbox: Available tools
- Scheduled Event: Trigger type, interval, and message content
- Wait & Combine: Name (rendezvous behavior is automatic)

#### Schedule Tab
View and manage scheduled events.

#### Voice Tab

**Voice Input (Speech-to-Text):**
- **Continuous Listening** â€“ Enable/disable wake word detection
- **Microphone Selection** â€“ Choose input device
- **Wake Words** â€“ Configurable phrases to activate voice input (e.g., "Hey Beezle")
- **Stop Words** â€“ Phrases to deactivate voice input (e.g., "Stop listening")
- **Max Recording Duration** â€“ Adjustable buffer size (5â€“60 seconds) for longer utterances

When enabled, the system listens continuously for wake words. Once detected, all subsequent speech is transcribed and sent to agents until a stop word is spoken. The max recording duration slider controls how much audio can be buffered before it's processedâ€”increase this if your speech is being cut off.

**Voice Output (Text-to-Speech):**
- Enable/disable TTS
- Voice selection (150+ Piper voices)
- Speed adjustment (0.5x - 2.0x)
- Speaker selection (for multi-speaker voices)

---

### 8. Knowledge Graph View (in Node Inspector)

When a Knowledge Graph node is selected, the Node Inspector displays:
- **Entities** â€“ Named objects with types and properties
- **Relationships** â€“ Connections between entities
- **Real-time updates** â€“ Watch the graph grow as agents learn
- **Selection details** â€“ Click to view entity/relationship properties

---

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- An LLM server (OpenAI-compatible API or local llama.cpp)

### Installation

```bash
# Clone the repository
git clone https://github.com/rhohndorf/beezle-bug.git
cd beezle-bug

# Start the services
docker compose up -d

# Frontend available at http://localhost:5173
# Backend API at http://localhost:5000
```

### First Agent Graph

1. **Create a Project** â€“ Click the folder icon â†’ "New Project"
2. **Add Nodes** â€“ Click "+" in the Node Graph tab
   - Add an **Agent** node
   - Add a **User Chat** node
   - Add a **User Display** node
3. **Connect Nodes** â€“ Drag from output ports to input ports
   - User Chat â†’ Agent (message)
   - Agent â†’ User Display (message)
4. **Configure Agent** â€“ Select the agent node and configure:
   - API URL: Your LLM endpoint (e.g., `http://127.0.0.1:1234/v1`)
   - Model: Your model name
   - Template: Choose a system template
5. **Deploy** â€“ Click the green "Deploy" button
6. **Chat** â€“ Switch to the Chat tab and start talking!

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend (React)                      â”‚
â”‚   NodeGraph â”‚ Chat â”‚ Templates â”‚ Settings â”‚ KnowledgeGraph  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Socket.IO
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Backend (Flask)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ ProjectMgr   â”‚  â”‚   Runtime    â”‚  â”‚   Storage    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                 â”‚                  â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚              Agent Graph Engine                  â”‚        â”‚
â”‚  â”‚  Agents â”‚ KnowledgeGraph â”‚ MemoryStream â”‚ Tools â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼              â–¼              â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚Local   â”‚    â”‚ OpenAI  â”‚    â”‚ LiteLLM â”‚
         â”‚llama   â”‚    â”‚   API   â”‚    â”‚         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
beezle-bug/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ beezle_bug/
â”‚   â”‚   â”œâ”€â”€ agent_graph/      # Agent graph models and runtime
â”‚   â”‚   â”œâ”€â”€ llm_adapter/      # LLM provider adapters
â”‚   â”‚   â”œâ”€â”€ memory/           # Knowledge graph & memory stream
â”‚   â”‚   â”œâ”€â”€ tools/            # Agent tools
â”‚   â”‚   â””â”€â”€ voice/            # TTS (Piper) and STT (Whisper)
â”‚   â””â”€â”€ server.py             # Flask + SocketIO server
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/       # React components
â”‚       â””â”€â”€ App.jsx           # Main application
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ projects/             # Saved projects
â”‚   â”œâ”€â”€ templates/            # Jinja2 system templates
â”‚   â””â”€â”€ voices/               # Piper TTS voice models
â””â”€â”€ docker-compose.yml
```

---

## ğŸ› ï¸ Available Tools

Agents can use these built-in tools:

| Category | Tools |
|----------|-------|
| **Knowledge Graph** | AddEntity, AddRelationship, AddPropertyToEntity, QueryEntities, QueryRelationships |
| **Memory** | AddObservation, RecallObservations, GetRecentObservations |
| **Web** | SearchWeb, SearchNews, ReadWebsite |
| **Filesystem** | ReadFile, WriteFile, ListDirectory |
| **System** | ExecuteCommand, RunPython |

---

## ğŸ”® Vision & Roadmap

### Autonomy âœ…
- [x] Continuous autonomous operation
- [x] Tool use and execution
- [x] Memory management

### Cooperation ğŸš§
- [x] Multi-agent task delegation
- [ ] Agent specialization

### Self-Improvement ğŸ”®
- [ ] Dynamic tool creation
- [ ] Self-fine-tuning

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Tad Williams for the [Otherland](https://en.wikipedia.org/wiki/Otherland) series
- [Piper TTS](https://github.com/rhasspy/piper) for local text-to-speech
- [faster-whisper](https://github.com/SYSTRAN/faster-whisper) for speech recognition
- [LiteLLM](https://github.com/BerriAI/litellm) for unified LLM API access
- [React Flow](https://reactflow.dev/) inspiration for the node graph
- The open-source AI community
